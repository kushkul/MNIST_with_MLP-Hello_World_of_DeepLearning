{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World of Deep Learning - Classifying Hand Written Digits using MLP\n",
    "\n",
    "In this notebook, we will build a Multi-layer Perceptron model to classify the hand written digits in a very famous MNIST dataset of images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data\n",
    "\n",
    "Following is the data used in this notebook: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "The MNIST database of handwritten digits, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting /mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#importing the packages\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Importing the data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/mnist_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the format of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.13725491, 0.5764706 , 0.80392164, 0.9686275 , 0.37254903,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01960784, 0.36078432, 0.98823535, 0.9686275 ,\n",
       "       0.48627454, 0.6901961 , 0.77647066, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02352941, 0.5372549 ,\n",
       "       0.9960785 , 0.8313726 , 0.27058825, 0.        , 0.10980393,\n",
       "       0.22352943, 0.2392157 , 0.20392159, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02745098, 0.6392157 , 0.9960785 , 0.8235295 , 0.19607845,\n",
       "       0.        , 0.        , 0.        , 0.05882353, 0.8941177 ,\n",
       "       0.73333335, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02745098, 0.53333336, 0.9960785 ,\n",
       "       0.8196079 , 0.09411766, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3921569 , 0.9960785 , 0.86666673, 0.04313726,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.32941177, 0.9960785 , 0.882353  , 0.09803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.454902  ,\n",
       "       0.9960785 , 0.80392164, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07450981, 0.8705883 , 0.95294124,\n",
       "       0.28627452, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.7843138 , 0.9960785 , 0.80392164,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.13333334, 0.9960785 , 0.80392164, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.38823533, 0.86274517,\n",
       "       0.9960785 , 0.9960785 , 0.80392164, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.13333334, 0.9960785 ,\n",
       "       0.9215687 , 0.33333334, 0.29411766, 0.29411766, 0.6039216 ,\n",
       "       0.94117653, 0.9960785 , 0.8745099 , 0.53333336, 0.9960785 ,\n",
       "       0.70980394, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00392157, 0.5019608 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.8862746 , 0.427451  ,\n",
       "       0.01960784, 0.13333334, 0.9960785 , 0.48235297, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3372549 , 0.64705884, 0.64705884, 0.5529412 ,\n",
       "       0.21960786, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.8078432 , 0.8078432 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0509804 , 0.882353  , 0.80392164,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.13333334, 0.9960785 , 0.5647059 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.38431376, 0.9960785 ,\n",
       "       0.48235297, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.454902  , 0.9960785 , 0.48235297, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.454902  ,\n",
       "       0.9960785 , 0.48235297, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.454902  , 1.        , 0.30588236,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.454902  , 0.9960785 , 0.16078432, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.454902  , 1.        ,\n",
       "       0.16078432, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.454902  , 0.9450981 , 0.10980393, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1691c2e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = mnist.train.images[8].reshape(28,28)\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Parameters\n",
    "\n",
    "**General Parameters **\n",
    "\n",
    "Following are the parameters we define for any deep learning model which defines the fundamental way in which it is trained and its performance. These parameters are unique for any given dataset and often we have to adjust the value of these parameters in order to get the best performance out of our model.\n",
    "\n",
    "* Learning Rate - The rate of change we allow for our gradients and hence cost function. The more is the learning rate the bigger are the steps taken by the algorithm in the desired direction by any optimization algorithm.\n",
    "* Training Epochs - Total number of times we train the network over the same data.\n",
    "* Batch Size - The size of a single batch in which the training data is divided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network Parameters **\n",
    "\n",
    "These are the parameters that actually determine the architecture of the Neural Network we are building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256       #no of hidden layer units in layer 1\n",
    "n_hidden_2 = 256       #no of hidden layer units in layer 2\n",
    "n_input = 784          #MNIST data (28pixels*28pixels)\n",
    "n_classes = 10         #Total output classes\n",
    "n_samples = mnist.train.num_examples      #total training examples\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Model\n",
    "\n",
    "A short description of the model that we are building:\n",
    "First we receive the input data array and then to send it to the first hidden layer. Then the data will begin to have a weight attached to it  between layers, which initially, is a random value, and then sent to a node to undergo an activation function. Then it will continue on to the next hidden layer until the final output layer. We just use two hidden layer in this model. \n",
    "\n",
    "Once the transformed data has reached the output layer we need to evaluate it. Here we will use a loss function to evaluate how far off we are from the desired resuslt. In this case, how many classes we got correct.\n",
    "\n",
    "Then we apply an optimization function to minimize the cost calculated in the last step. This is done by adjusting the weights across the network. In this example we are using Adam Optimizer.\n",
    "\n",
    "We can adjust how quickly to apply to apply this optimization to the weights by changing the learning rate that we defined before. Lower the rate, higher is the possibility of accuracyand hence resolution , but slower is the process of optimization and longer it takes to get to the desired level of accuracy. The higher the rate, quicker is the optimization at the cost of resolution and we may end up diverging from the results.\n",
    "\n",
    "The two hidden layers are using Relu activation function, which is a simple rectifier function which either returns 0 or x. Final output layer will use linear activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    This function provides the definition of the activation functions of different layers.\n",
    "    \n",
    "    Arguments:\n",
    "    x: Input tensor of images.\n",
    "    weights: Randomly initialized weights of the network\n",
    "    biases: Randomly initialized bias used along with the weights.\n",
    "    \n",
    "    Returns:\n",
    "    Values calculated by the output layer.\n",
    "    '''\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return(out_layer)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Bias Initialization\n",
    "\n",
    "In order for our Tensorflow model to work, we need to create two dictionaries containing our weight and bias objects for the model. We use the tf.variable object type as this is different from a constant beacause Tensorflow's Graph Object becomes aware of the states of all the variables. A variable is a modifiable\n",
    "tensor that lives in Tensorflow's graph of interacting operations. It can be used and modified by the computation. \n",
    " \n",
    "We use Tensorflow's built-in random_normal method to create random values for our weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1' : tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2' : tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_classes])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing the model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Cost and Optimization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-b374c41cb3d8>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "**next_batch() **\n",
    "\n",
    "This function returns a tuple in the form (X, y) with an array of the data and a y-array indicating the class in the form of a binary array. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsamp, ysamp = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1713f588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(ysamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the session\n",
    "\n",
    "We are running two loops, the outer loop runs the epochs, and the inner loop runs the batches for each epoch loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 244.3472\n",
      "Epoch: 2 cost = 62.3130\n",
      "Epoch: 3 cost = 39.7146\n",
      "Epoch: 4 cost = 27.9063\n",
      "Epoch: 5 cost = 20.6999\n",
      "Epoch: 6 cost = 15.8351\n",
      "Epoch: 7 cost = 12.5259\n",
      "Epoch: 8 cost = 10.0443\n",
      "Epoch: 9 cost = 8.6843\n",
      "Epoch: 10 cost = 6.7937\n",
      "Epoch: 11 cost = 5.5356\n",
      "Epoch: 12 cost = 4.7222\n",
      "Epoch: 13 cost = 4.0170\n",
      "Epoch: 14 cost = 3.3891\n",
      "Epoch: 15 cost = 2.8537\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "#Launch the session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#Initialize all the variables\n",
    "sess.run(init)\n",
    "\n",
    "#Training epochs\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    #Starting with Cost = 0.0\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    #Convert total number into batches\n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    \n",
    "    #Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        #Get the next batch of data and labels\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        #Feed dictionary for optimization and loss value\n",
    "        #Returns a tuple, but we need only the cost.\n",
    "        _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y: batch_y})\n",
    "        \n",
    "        #compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(\"Epoch: {} cost = {:.4f}\".format(epoch+1, avg_cost))\n",
    "    \n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluations\n",
    "\n",
    "Tensorflow comes with some in-built functions to help evaluate the model, like, tf.equal, tf.cast and tf.reduce_mean\n",
    "\n",
    "**tf.equal() **\n",
    "\n",
    "This is essentially just a check of predictions == y_test. In this case since we know the format of the labels is a 1 in an array of zeros, we can argmax() location of that 1. Remember that y is still that placeholder we created at the very beginning, we will perform a series of operations to get a tensor that we can eventually fill in the test data for with an evaluation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Model\n",
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a numerical value for our predictions we will need to use tf.cast to cast the Tensor of booleans back into a Tensor of floating point values in order to take the mean of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use tf.reduce_mean() in order to grab the mean of the elements across the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy is still a Tensor object. We still need to pass in our actual test data. Now we call the mnist test labels and images and evaluate our accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eval() method allows us to directly evaluate this tensor in a Session without needing to call tf.Sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9495\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic MLP classifier is able to achieve ~95% accuracy. This can be increased by increasing the total hidden layers, but this will also lead to increase in run time of the model training. Other way to increase the accuracy of the model is to increase the total number of epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
